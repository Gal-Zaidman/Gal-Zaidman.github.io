[{"categories":["Golang"],"contents":"Most of the communication that happens over REST involves passing data as JSON. JSON is a language-independent data format, but when we use it in our programs it is basically a string.We need to make sure that our JSON string is always valid JSON object this can be hard when we have a complex Struct that contains many fields. Marsheling and Unmarshaling objects helps us achieve that. Marsheling is the operation of converting Go objects into JSON strings. Unmarshalling is the operation of converting JSON strings into Go objects.\nThe first step is to add support for json to our struct:\ntype User struct { Fname string `json:\u0026#34;fname\u0026#34;` Lname string `json:\u0026#34;lname\u0026#34;` } We need to tell GO what is the name of the field in the JSON format and to which filed it correlates. To convert it to a JSON we use the json.Marshal method from the encoding/json package:\nfunc (u User) toJSON() string { byteArray, err := json.Marshal(book) if err != nil { // HANDLE  } return string(byteArray) } When we want to Unmarshal the object we use the json.Unmarshal method which receives a byte array containing the JSON and a pointer to the var object to populate:\nfunc Unmarshal(data []byte, v interface{}) error For example:\nfunc jsonToUser(j string) *User { var p User err := json.Unmarshal([]byte(jsonString), \u0026amp;p) if err != nil { // HANDLE  } return \u0026amp;p } Faster JSON Marshal and Unmarshal: The JSON marshaling and unmarshaling provided by the encoding/json package uses reflection to figure out values and types each time. Reflection, provided by the reflect package, takes time to figure out types and values each time a message is acted on (in Go is fairly fast). If you’re repeatedly acting on the same structures, quite a bit of time will be spent reflecting. Additionally, reflection allocates memory that needs to be garbage-collected, and there’s a small computational cost to that as well.\nThere are a number of packages outside the standard library that aim to solve this problem. In this blog post we will cover the Codec Package which is very fast and popular but there are other good alternatives that will not be covered here such as:\n easyjson ffjson  The reason I choose to talk about Codec is that it is just considered more stable (currently as time goes by things will change).\nCodec The package github.com/ugorji/go/codec, provides a High Performance codec/encoding library for binc, msgpack, cbor and json formats.\nIt is important to note that with all its benefits it is not always safe to use codec, and you should look at the documentation for warnings. At the time of writing Codec is NOT safe for concurrent use, and state that the usage model is basically:\n Create and initialize the Handle before any use. Once created, DO NOT modify it. Multiple Encoders or Decoders can now use the Handle concurrently. They only read information off the Handle (never write). However, each Encoder or Decoder MUST not be used concurrently To re-use an Encoder/Decoder, call Reset(\u0026hellip;) on it first. This allows you use state maintained on the Encoder/Decoder.  Look at Usage for updates.\nThe first thing we need to do is to install the package with go get:\ngo get github.com/ugorji/go/codec/codecgen To use it we first need to define our struct with the codec tag (instead of JSON):\n// go:generate codecgen -o user_generated.go user.go  type User struct { Fname string `codec:\u0026#34;fname\u0026#34;` Lname string `codec:\u0026#34;lname\u0026#34;` } When we run:\ngo generate ./ go generate will see the first comment line of the file, which is specially formatted for it, and execute codecgen. The output file is named user_generated.go. In the generated file, you’ll notice that two public methods have been added to the User type:\n CodecEncodeSelf CodecDecodeSelf  When these are present, the codec package uses them to encode or decode the type. When they’re absent, the codec package falls back to doing these at runtime.\nfunc (u User) toJSON() string { jh := new(codec.JsonHandle) var out []byte err := codec.NewEncoderBytes(\u0026amp;out, jh).Encode() if err != nil { // HANDLE  } return string(byteArray) } func jsonToPerson(j string) *Person { jh := new(codec.JsonHandle) var p User err := json.NewDecoderBytes(j, jh).Decode(\u0026amp;p) if err != nil { // HANDLE  } return \u0026amp;p } ","permalink":"https://gal-zaidman.github.io/blog/golang/json-marshal-and-unmarshal/","tags":["Golang","JSON"],"title":"JSON Marsheling and Unmarshaling"},{"categories":["Golang"],"contents":"Before we start This tutorial was created while implementing a small project that required web crawling. It is composed from various descriptions, definitions and examples I saw on the links in the References section as well as my own experience while working on the project.\nWhat is a web crawler? Essentially, a web crawler is a tool that inspects the HTML of a givin web page and performs some type of actions based on that content. On the simple case (which is what we will implement in this tutorial) the web crawler start from a simple page, and while scanning that page it acquire more links to visit. Lets look at the following pseudo code to better understand the basics:\nQueue = Queue() Queue.Add(initialURL) while Queue is not empty: URL = Queue.pop() Page = Visit(URL) Links = ExtractURLs(Page) for link in Links: Queue.Add(link) Usually when we think of writing wab crawlers the first language tha comes to mind is python, with its wide selection of frameworks and rich data processing abilities, however Golang has a very good rich ecosystem for web crawling as well that lets you utilize the efficiency of Golang.\nColly - The golang web crawling framework Introduction Colly is a Golang framework for building web scrapers. With Colly you can build web scrapers of various complexity, from simple scraper to complex asynchronous website crawlers processing millions of web pages. Colly is very much \u0026ldquo;Batteries-Included\u0026rdquo;, meaning you will get the most required features \u0026ldquo;Out of the box\u0026rdquo;. Colly has a rich API with features such as:\n Manages request delays and maximum concurrency per domain Automatic cookie and session handling Sync/async/parallel scraping Distributed scraping Caching Automatic encoding of non-unicode responses  To install Colly we need to have Golang installed and run:\ngo get -u github.com/gocolly/colly/... Then in our go file we need to import it:\nimport \u0026#34;github.com/gocolly/colly\u0026#34; Latest info can be found in colly installation guide\nBasic Components Collector Colly’s main entity is the Collector struct. The Collector keep track of pages that are queued to visit, manages the network communication and responsible for the execution of the attached callbacks when a page is being scraped.\nTo initialize a Collector we need to call the NewCollector function:\n// Create a collector with the default configuration c := colly.NewCollector() The NewCollector function definition is\nfunc NewCollector(options ...CollectorOption) *Collector CollectorOption is a function which accepts a pointer to a Collector and configures it\ntype CollectorOption func(*Collector) We can basically configure each field in the Collector struct, for example here is a collector that is Asynchronous and will only go to links on the starting page:\nc := colly.NewCollector( // MaxDepth is 2, so only the links on the scraped page  // and links on those pages are visited  colly.MaxDepth(2), colly.Async(true), ) Important Notes:\n We can override our configuration at any point. We can use environment variables to configure our collector, this is useful if we don\u0026rsquo;t want to recompile the program for customizing the collector, but we need to remember that every configuration that is defined in our program will override our environment variable.  You can see the full list of CollectorOption functions in colly goDocs and for more detailed information about how we can configure the collector go the the colly configuration docs\nCallbacks Colly gives us a number of callbacks that we can setup. Those callbacks will be called on various stages in our crawling job and you will need to think which one do you want based on you requirements. Here is a list of all the callbacks and the order in which they will be called (taken from the colly website[1]):\n OnRequest(f RequestCallback) - Called before a request. OnError(f ErrorCallback) - Called if error occured during the request. OnResponse(f ResponseCallback) - Called after response received. OnHTML(goquerySelector string, f HTMLCallback) - Called right after OnResponse if the received content is HTML. OnXML(xpathQuery string, f XMLCallback) - Called right after OnHTML if the received content is HTML or XML. OnScraped(f ScrapedCallback) - Called after OnXML callbacks.  Each of those callbacks receive a function which will be triggered when the callback is called.\nNow that we understand the basics of colly, lets dive into our project\nOur project Overview So under the openshift organization we have various github repos. Merged PRs will trigger a release build. Whenever QE needs to verify a Bug which is resolved in a certain PR they need to manually look at when the PR was merged and then go to Openshift release page and find a release job which was triggered after the time the PR was merged, check its page and see that it contains a the PR and then they know that they can use the release for verification. We want to automate this task.\nWe will build a small project that checks when a PR was merged, and then crawl on the openshift release page and find the release which contain the PR.\nLogic  Retrieve the PR from the user. Validate that it is a github PR link. Find when the PR was merged. Find all the links to release pages on the openshift release. On each link search for the PR ID.  Implementation So we will use:\n flags - for parsing our commend line args. regexp - to validate the pattern of a github repo. github api - to retrieve the PR data.  Our main function will look like:\nfunc main() { var err error debug := flag.Bool(\u0026#34;debug\u0026#34;, false, \u0026#34;run with debug\u0026#34;) flag.Parse() url := flag.Arg(0) prd, err = newPullRequestData(url) if err != nil { panic(err) } setupReleasePageCrawler(*debug) setupReleaseStatusCrawler(*debug) releaseStatusCrawler.Visit(\u0026#34;https://\u0026#34; + OPENSHIFT_RELEASE_DOMAIN) releasePageCrawler.Wait() fmt.Println(\u0026#34;Done!\u0026#34;) } We get the URL from the user and also configure a flag for running in DEBUG mode. Then we get the PR details and configure our crawlers\n releaseStatusCrawler will be in charge of parsing the release domain and finding relevant release pages. releasePageCrawler will be in charge of finding the PR in the release page.  And at the end we visit the release page, and call the Wait function on releasePageCrawler since it will run asynchronously.\nFirst of all, lets create a struct that will hold all of the data which we need for a PR.\n// PullRequestData holds all the data needed for a PR type PullRequestData struct { org string repo string id int mDate time.Time } Then write a the logic for getting a PR Url and creating a PullRequestData object.\n// Gets a PR URL and returns the organization, repo and ID of that PR. // If the URL is not a valid PR url then returns an error func parsePrURL(prURL string) (string, string, int, error) { githubReg := regexp.MustCompile(`(https*:\\/\\/)?github\\.com\\/(.+\\/){2}pull\\/\\d+`) if !githubReg.MatchString(prURL) { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, 0, fmt.Errorf(\u0026#34;ERROR: prURL is not a github PR URL, got url %v\u0026#34;, prURL) } u, err := url.Parse(prURL) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, 0, err } pArr := strings.Split(u.Path, \u0026#34;/\u0026#34;) if len(pArr) != 5 { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, 0, fmt.Errorf(\u0026#34;Expected PR URL with the form of github.com/ORG/REPO/pull/ID, but instead got %v\u0026#34;, prURL) } id, err := strconv.Atoi(pArr[4]) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, 0, fmt.Errorf(\u0026#34;ERROR: Expected PR URL with the form of github.com/ORG/REPO/pull/ID, but instead got %v\u0026#34;, prURL) } return pArr[1], pArr[2], id, nil } // Creates a Github client using AccessToken if it exists or an un authenticated client // if no AccessToken is available and retrieves the PR details from github func getGithubPrData(org string, repo string, id int) (*github.PullRequest, error) { var client *github.Client ctx := context.Background() accessToken := os.Getenv(\u0026#34;AccessToken\u0026#34;) if accessToken == \u0026#34;\u0026#34; { client = github.NewClient(nil) } else { ts := oauth2.StaticTokenSource( \u0026amp;oauth2.Token{AccessToken: accessToken}, ) tc := oauth2.NewClient(ctx, ts) client = github.NewClient(tc) } pr, _, err := client.PullRequests.Get(ctx, org, repo, id) return pr, err } func newPullRequestData(prURL string) (*PullRequestData, error) { org, repo, id, err := parsePrURL(prURL) if err != nil { return \u0026amp;PullRequestData{}, err } pr, err := getGithubPrData(org, repo, id) if err != nil { return \u0026amp;PullRequestData{}, err } return \u0026amp;PullRequestData{ org: org, repo: repo, id: id, mDate: pr.GetMergedAt(), }, nil } Here we get a PR URL, then call parsePrURL which validates that the URL is correct and returns the organization, repository and id from the URL. After we retrieved the fields from the PR URL we call getGithubPr which creates a github client and uses github API for getting the PR details. Finally we return a pointer to a PullRequestData object.\nNow lets configure our first crawler, the release status crawler. The release status crawler works on one page only, the OCP release page which contains ~2000+ links.\nfunc setupReleaseStatusCrawler(debug bool) { releaseStatusCrawler = colly.NewCollector( colly.AllowedDomains(OPENSHIFT_RELEASE_DOMAIN), colly.MaxDepth(1), ) if debug == true { releaseStatusCrawler.OnRequest(func(r *colly.Request) { fmt.Println(\u0026#34;Debug: release status crawler is visiting: \u0026#34;, r.URL.String()) }) } releaseStatusCrawler.OnHTML(\u0026#34;a[href]\u0026#34;, filterReleasesLinks) } Here we create a new crawler that can visit only ocp domain and set MaxDepth to 1 so it will stay only one first link. Then we will use the OnRequest callback to print the URL we are visiting in debug mod. Finally we use the OnHTML callback to set a function that will be called on each a[href] object. filterReleasesLinks is a function of type HTMLCallback. It gets the a[href] object and triggers the releasePageCrawler (which works on async mode) if that element fits the release regex and is created after the PR is merged.\nfunc filterReleasesLinks(e *colly.HTMLElement) { reRelease := regexp.MustCompile(`\\d\\.\\d\\.\\d-\\d\\.(nightly|ci)-\\d{4}-\\d{2}-\\d{2}-\\d{6}`) if !reRelease.MatchString(e.Text) { return } d := strings.SplitN(e.Text, \u0026#34;-\u0026#34;, 3)[2] d = strings.Split(d, \u0026#34; \u0026#34;)[0] tr, err := time.Parse(PR_DATE_FORMAT, d) if err != nil { fmt.Printf(\u0026#34;Error time.Parse: \u0026#34;, err) } // Check if PR merge time t is after the release creation time tr \tif prd.mDate.After(tr) { return } link := e.Attr(\u0026#34;href\u0026#34;) releasePageCrawler.Visit(e.Request.AbsoluteURL(link)) } Now lets configure our second crawler, the release page crawler. The release page crawler works on one page only, the release page which should contain a link to the given PR. The release page crawler will be triggered by the release status crawler when it finds a relevant link, so it needs to work on Async mode.\nfunc setupReleasePageCrawler(debug bool) { releasePageCrawler = colly.NewCollector( colly.AllowedDomains(OPENSHIFT_RELEASE_DOMAIN), colly.MaxDepth(1), colly.Async(true), ) //Set max Parallelism and introduce a Random Delay \treleasePageCrawler.Limit(\u0026amp;colly.LimitRule{ Parallelism: 6, RandomDelay: 1 * time.Second, }) if debug == true { releasePageCrawler.OnRequest(func(r *colly.Request) { fmt.Println(\u0026#34;Debug: release page crawler is visiting: \u0026#34;, r.URL.String()) }) } releasePageCrawler.OnHTML(\u0026#34;a[href]\u0026#34;, findPR) } Here we create a new crawler that can visit only ocp domain ,set MaxDepth to 1 so it will stay only on the first link and configure it to work in Async mode. Then we set a limit to be a good citizen of the web, this is important because websites can block users that overload the site. Then we will use the OnRequest callback to print the URL we are visiting in debug mod. Finally we use the OnHTML callback to set a function that will be called on each a[href] object. findPR is also a HTMLCallback function. It gets the a[href] object and if it is a valid PR URL checks if it has the same ID as the given PR. If the IDs match we know that we found a release which contains our PR and we print it for the user.\nfunc findPR(e *colly.HTMLElement) { link := e.Attr(\u0026#34;href\u0026#34;) _, _, id, err := parsePrURL(link) if err != nil { return } if prd.id == id { fmt.Println(\u0026#34;found release, link \u0026#34;, e.Request.URL.String()) } } The full code can be found on: https://github.com/Gal-Zaidman/ocp-release-finder\nReferences: [1] Colly web page and docs [2] Scraping the Web in Golang with Colly and Goquery\n","permalink":"https://gal-zaidman.github.io/blog/golang/web-crawling-in-go-with-colly-learn-go-by-doing/","tags":["Golang","WebCrawling","Colly"],"title":"Web Crawling In Golang With Colly"},{"categories":["Ansible","Full course"],"contents":"Playbooks are the main power of ansible. I like to think of a playbook as an easy to manage script. Playbooks allow us to run multiple sets of tasks called plays, define variables and add logic such as conditions and loops.\nThis is an example of a very basic playbook:\n---- name:firstplayhosts:web.example.com#The host must be selected from the inventoryvars:# some variable definitions]#configurations for exampleorder: # The order in which hosts are selected, options:inventory,reverse_inventory,sorted,reverse_sortedandshuffleremote_user:rootbecome:truehosts:tasks:- name:firsttaskyum:name:httpdstatus:present- name:secondtaskservice:name:httpdenabled:true- name:secondplayhosts:database.example.comtasks:- name:firsttaskservice:name:mariadbenabled:true...So to clarify the terminology:\n task: a single action in the playbook, each task uses a single ansible module to perform the action. play: ordered set of tasks. playbook: text file containing a list of one or more plays to run in a specific order.  In the example we see a playbook that contains 2 plays, this playbook is a simple YAML file that the ansible command can get as an input and run. Like any languadge ansible playbooks have specific syntax we need to use when writing them, here are some points we need to keep in mind:\n Playbooks are written in YAML format. Uses indentation with space characters (tab characters are not allowed) a convention is to use 2 spaces for indentation, but it can be more. Can use blank lines for readability. Data elements at the same level in the hierarchy must have the same indentation. Items that are children of another item must be indented more than their parents. Begins with a line consisting of three dashes (\u0026mdash;) as a start of document marker, and optionally ends with three dots (\u0026hellip;). Multi line strings can be written in 2 ways:   vertical bar (|) - newline characters within the string are preserved.\n  greater-than (\u0026gt;) - newline characters are to be converted to spaces and that leading white spaces are removed.\ninclude_newlines:| Example Company123MainStreetAtlanta,GA30303fold_newlines:\u0026gt; This is an exampleofalongstring,thatwillbecomeasinglesentenceoncefolded.    To verify that the syntax is correct:\nansible-plybook --syntax-check ** See Ansible docs for more examples and clarification.\nRemote Users and Privilege Escalation in Plays Plays can override the user and privileges set on the configuration file. The following keys are available for configuration within a play:\n remote_user become boolean - enable or disable privilege escalation. become_method - define the privilege escalation method. become_user - the user account to use for privilege escalation.  Running Playbooks To run an ansible playbook we just use the ansible-playbook command:\nansible-playbook PLAYBOOK_FILE We can run a playbook as dry-run to see what would happen without really change anything on the hosts:\nansible-playbook -C PLAYBOOK_FILE We can also change the verbosity level:\n -v The task results are displayed. -vv Both task results and task configuration are displayed. -vvv Includes information about connections to managed hosts. -vvvv Adds extra verbosity options to the connection plug-ins, including users being used in the managed hosts to execute scripts, and what scripts have been executed.  One of the most important features of playbooks is that it should be safe to re-running. Meaning that if a specific task needs to do something that as already been done it will not be executed, this saves us a lot of problems.\nMost ansible modules are safe to re-run and that makes our life easier when writing the playbook, but we need to keep in mind that some modules are not safe like the command and shell modules. We need to be careful when writing a playbook that uses unsafe modules and add some condition to not run the task in case the desired outcome as already been reached.\nAnsible Variables Ansible variables are the same as any other language they are used to store values that can be reused, or hold outputs from previous commands. This can simplify the creation and maintenance of a playbook. In the above example we saw a very simple playbook that installed the httpd package and restarted the httpd service, we could have used a variable to hold the httpd value.\nVariables can be defined in many places but the main scopes are:\n Global scope - set from the command line or Ansible configuration.  ansible-playbookmain.yml-e\u0026#34;package=apache\u0026#34; Play scope - set in the play and related structures.\n Vars block at the beginning of a play:  - hosts:allvars:user:joehome:/home/joe variables in external files. the vars_files contains a list of names for external variable files relative to the location of the playbook:  # playbook:...- hosts:allvars_files:- vars/users.yml...# cat users.yml:user:joehome:/home/joe  Host scope:\n   set on host groups and individual hosts by the inventory (like we saw on part 2). fact gathering - When ansible logs into a host he gathers facts about this host. The facts are saved into several variables that can be used within the playbook. See facts and discovered system facts registered tasks - When we run a task we can register the result of that task as a variable  - hosts:web_serverstasks:- shell:/usr/bin/fooregister:foo_resultignore_errors:True- shell:/usr/bin/barwhen:foo_result.rc==5Magic variables - contain information about Ansible operations, including the python version being used, the hosts and groups in inventory, and the directories for playbooks and roles. The most commonly used magic variables are hostvars, groups, group_names, and inventory_hostname, see all on Magic variables ans examples on Accessing information about other hosts with magic variables  ** ansible variables must start with a letter and can only contain letters, numbers, and underscores.\nA variable can be:\n string: number: list: dictionary:  vars:user:joe#stringid:1# numberfriends_list:# list- cartman- kennyfriends_dict:# dictionarybest:kennyfunnest:cartmanThe difference between a list and a dictionary, is that list variables are accessed with an index like friends_list[0] and dictionary variables are accessed with a key like friends_dict[\u0026lsquo;best\u0026rsquo;] or friends_dict.best\nUsing variables To use the variable in a task we wrap it with curly braces {{ }}, note that we need to use quotes \u0026quot;\u0026rdquo; when a variable is used as the first element:\ntasks:# No need for quotes \u0026#34;\u0026#34; since user is not the first element- name:Createstheuser{{user}}user:# Need quotes \u0026#34;\u0026#34; since user is the first elementname:\u0026#34;{{ user }}\u0026#34;Variables precedence From least to greatest (the last listed variables winning prioritization):\n command line values (eg “-u user”) role defaults [1] inventory file or script group vars [2] inventory group_vars/all [3] playbook group_vars/all [3] inventory group_vars/* [3] playbook group_vars/* [3] inventory file or script host vars [2] inventory host_vars/* [3] playbook host_vars/* [3] host facts / cached set_facts [4] play vars play vars_prompt play vars_files role vars (defined in role/vars/main.yml) block vars (only for tasks in block) task vars (only for the task) include_vars set_facts / registered vars role (and include_role) params include params extra vars (always win precedence)  Writing Loops and Conditional Tasks Loops When we write a script we often need to preform some actions multiple times, pull/skip a task until a certain condition is met. Ansible lets you do this with loops and conditional tasks.\nWe can iterate a task over a set of items using the loop keyword. The loop keyword is added in the task level, and takes as a value a list or dictionary of items over which the task should be iterated. The variable {{ item }} holds the value used during each iteration.\nExample:\n# Using list- name:firewalldandsshdarerunningservice:name:\u0026#34;{{ item }}\u0026#34;state:startedloop:- firewalld- sshd# Using dictionary- name:Usersexistandareinthecorrectgroupsuser:name:\u0026#34;{{ item.name }}\u0026#34;state:presentgroups:\u0026#34;{{ item.groups }}\u0026#34;loop:- name:cartmangroups:wheel- name:kennygroups:rootConsult the documentation for more advanced looping scenarios link.\nRegistering variables with a loop You can register the output of a loop as a variable. For example:\n- shell:\u0026#34;echo {{ item }}\u0026#34;loop:- \u0026#34;one\u0026#34;- \u0026#34;two\u0026#34;register:echoWhen you use register with a loop, the data structure placed in the variable will contain a results attribute that is a list of all responses from the module.\nConditional Tasks Ansible can use conditionals to execute tasks or plays when certain conditions are met. Playbook variables, registered variables, and Ansible facts can all be tested with conditionals. Operators to compare strings, numeric data, and Boolean values are available.\nThe when statement is used to run a task conditionally. In the when statement we define the condition or conditions that needs to be meet the execute the task. We can use and, or, () to combine multiple conditions\n---- name:SimpleBooleanTaskDemohosts:allvars:s_name:my_servicetasks:- name:\u0026#34;{{ s_name }} is started when there is enough memory\u0026#34;service:name:\u0026#34;{{ s_name }}\u0026#34;state:startedwhen:- ansible_memfree_mb\u0026gt;8192- ansible_distribution==\u0026#34;RedHat\u0026#34;Example Conditionals: Equal (value is a string) | ansible_machine == \u0026#34;x86_64\u0026#34; Equal (value is numeric) | max_memory == 512 Numeric comparessions | \u0026lt; | \u0026gt; | \u0026lt;= | =\u0026gt; | != Variable exists | min_memory is defined Variable does not exist | min_memory is not defined Boolean variable is true | memory_available Boolean variable is false | not memory_available element in linst |\tansible_distribution in supported_distros # OR - when: ansible_distribution == \u0026#34;RedHat\u0026#34; or ansible_distribution == \u0026#34;Fedora\u0026#34; # And - when: ansible_distribution_version == \u0026#34;7.5\u0026#34; and ansible_kernel == \u0026#34;3.10.0-327.el7.x86_64\u0026#34; - when: - ansible_distribution_version == \u0026#34;7.5\u0026#34; - ansible_kernel == \u0026#34;3.10.0-327.el7.x86_64\u0026#34; # Combine conditions - when: \u0026gt; ( ansible_distribution == \u0026#34;RedHat\u0026#34; and ansible_distribution_major_version == \u0026#34;7\u0026#34; ) or ( ansible_distribution == \u0026#34;Fedora\u0026#34; and ansible_distribution_major_version == \u0026#34;28\u0026#34; ) Ansible Handlers Playbooks have a basic event system that can be used to respond to changes made by tasks in the playbook. These ‘events’ are used to notify the playbook on certain actions and they are triggered by the notify keyword. The events are triggered at the end of each block of tasks in a play, and will only be triggered once even if notified by multiple different tasks.\nEach event or ‘notify‘ statment can have a handler to handle the event. Handlers are tasks that respond to a notification triggered by other tasks. Handlers can be considered as inactive tasks that only get triggered when explicitly invoked using a notify statement.\nExample: Apache server is only restarted by the restart apache handler when a configuration file is updated and notifies it:\ntasks:- name:copydemo.example.confconfigurationtemplatetemplate:src:/var/lib/templates/demo.example.conf.templatedest:/etc/httpd/conf.d/demo.example.confnotify:- restartapachehandlers:- name:restartapacheservice:name:httpdstate:restartedSome notes to keep in mind:\n Tasks only notify their handlers when the task changes something on a managed host. Use unique handler names. If you trigger more than one handler with the same name, the first one(s) get overwritten. Only the last one defined will run. Each handler is triggered at the end of a block of tasks in a playbook. If more than one task notifies a handler, the handler only runs once after all other tasks in the block have completed. If no tasks notify it, a handler will not run. A task may call more than one handler in its notify section. Handlers always run in the order specified by the handlers section of the play. They do not run in the order in which they are listed by notify statements in a task, or in the order in which tasks notify them. Handlers normally run after all other tasks in the play complete. A handler called by a task in the tasks part of the playbook will not run until all tasks under tasks have been processed. (There are some minor exceptions to this.)  IMPORTANT Handlers are meant to perform an extra action when a task makes a change to a managed host. They should not be used as a replacement for normal tasks.\nHandling Errors on a Play Ansible evaluates the return code of each task to determine whether the task succeeded or failed. Normally, when a task fails Ansible immediately aborts the rest of the play on that host, skipping all subsequent tasks. However, sometimes you might want to have play execution continue even if a task, there are a number of approaches to this, depending on the desired outcome:\n  Ignoring Task Failure: We can ignore failed tasks with the ignore_errors keyword.\nname:Latestversionofnotapkgisinstalledyum:name:notapkgstate:latestignore_errors:yes  Forcing Execution of Handlers after Task Failure:\nNormally when a task fails and the play aborts on that host, any handlers that had been notified by earlier tasks in the play will not run. If you set force_handlers: yes on the play, then notified handlers are called even if the play aborted because a later task failed.\nhosts:allforce_handlers:yestasks:- name:ataskwhichalwaysnotifiesitshandlercommand:/bin/truenotify:restartthedatabase- name:ataskwhichfailsbecausethepackagedoesn\u0026#39;texistyum:name:notapkgstate:latesthandlers:- name:restartthedatabaseservice:name:mariadbstate:restarted  Specifying Task Failure Conditions:\nYou can use the failed_when keyword on a task to specify which conditions indicate that the task has failed. This is often used with command modules that may successfully execute a command, but the command\u0026rsquo;s output indicates a failure.\ntasks:- name:Runusercreationscriptshell:/usr/local/bin/create_users.shregister:command_resultfailed_when:\u0026#34;\u0026#39;Password missing\u0026#39; in command_result.stdout\u0026#34;The fail module can also be used to force a task failure. The above scenario can alternatively be written as two tasks:\ntasks:- name:Runusercreationscriptshell:/usr/local/bin/create_users.shregister:command_resultignore_errors:yes- name:Reportscriptfailurefail:msg:\u0026#34;The password is missing in the output\u0026#34;when:\u0026#34;\u0026#39;Password missing\u0026#39; in command_result.stdout\u0026#34;You can use the fail module to provide a clear failure message for the task. This approach also enables delayed failure, allowing you to run intermediate tasks to complete or roll back other changes.\n  Specifying When a Task Reports “Changed” Results:\nThe changed_when keyword can be used to control when a task reports that it has changed.\n- name:getKerberoscredentialsas\u0026#34;admin\u0026#34;shell:echo\u0026#34;{{ krb_admin_pass }}\u0026#34;|kinit-fadminchanged_when:false# changed_when: false == only reports ok or failed.tasks:- shell:cmd:/usr/local/bin/upgrade-databaseregister:command_resultchanged_when:\u0026#34;\u0026#39;Success\u0026#39; in command_result.stdout\u0026#34;notify:- restart_databasehandlers:- name:restart_databaseservice:name:mariadbstate:restarted  Ansible Blocks and Error Handling:\nIn playbooks, blocks can be used to control how tasks are executed. For example, a task block can have a when keyword to apply a conditional to multiple tasks:\n- name:blockexamplehosts:alltasks:- name:installingandconfiguringYumversionlockpluginblock:- name:packageneededbyyumyum:name:yum-plugin-versionlockstate:present- name:lockversionoftzdatalineinfile:dest:/etc/yum/pluginconf.d/versionlock.listline:tzdata-2016j-1state:presentwhen:ansible_distribution==\u0026#34;RedHat\u0026#34;Blocks also allow for error handling in combination with the rescue and always statements. If any task in a block fails, tasks in its rescue block are executed in order to recover.\n block: Defines the main tasks to run. rescue: Defines the tasks to run if the tasks defined in the block clause fail. always: Defines the tasks that will always run independently of the success or failure of tasks defined in the block and rescue clauses.  tasks:- name:UpgradeDBblock:- name:upgradethedatabaseshell:cmd:/usr/local/lib/upgrade-databaserescue:- name:revertthedatabaseupgradeshell:cmd:/usr/local/lib/revert-databasealways:- name:alwaysrestartthedatabaseservice:name:mariadbstate:restartedNote that a condition on a block also applies to its rescue and always if present.\n  ","permalink":"https://gal-zaidman.github.io/blog/ansible/3.-writing-and-running-playbooks/","tags":["Ansible","FullCourse","GettingStarted"],"title":"Writing and Running Playbooks"},{"categories":["Ansible","Full course"],"contents":"When we use ansible we often need to manage remote hosts, those hosts can be bare-metals, VMs, instances running on different clouds and so on. Before we start writing playbooks and tasks (will be covered later) we need to understand what infrastructure we have and how should we manage it, this will have an affect on how our playbooks will be structured. In this part we will talk about the ansible inventory, which is a file that lists the hosts we manage with the ansible playbook, learn how to define host specific variables and cover some configurations that are relevant to the way we talk to our hosts.\nAnsible Inventory The ansible inventory is mostly a list of hosts that we want to manage with ansible. It allows us to easily group a number of hosts under the same name, and define variables for each host/group.\nIn ansible there are 2 types of inventories:\n static: a regular file that can be written in INI or YAML format. This is the most common and simple inventory and will be the main focus of this blog. dynamic: an executable script that returns a generated static inventory that reflects the current state of the infrastructure. This is a more advanced type of inventory which will be covered briefly.  Inventory Structure The simplest inventory is just a file listing the hosts. For example this is a simple inventory that lists 5 hosts with their FQDN:\nhost1.example.gzaidman.com # dev host host2.example.gzaidman.com # test host3.example.gzaidman.com # test host4.example.gzaidman.com # prod host5.example.gzaidman.com # prod ** We could also use plain IP addresses, but as a best practice it is recommended to use FQDN or or IP addresses with aliases.\nThe above could be shortened with ranges:\nhost1.example.gzaidman.com # dev host host[2:3].example.gzaidman.com # test host[4:5].example.gzaidman.com # prod When we run an ansible playbook with the above inventory, ansible will try to perform each task in the playbook on all the hosts in the inventory.\nHaving a simple inventory with 5 hosts is not elegant but is manageable, but what if we have 50? 100? 1000?? as our infrastructure grows bigger and the system becomes more complex it is clear that we need a better way to organize our hosts, that\u0026rsquo;s where inventory groups come into play.\nAnsible inventory groups are used to assign a label to a collection of hosts. For example, we can use groups in the above example:\n[dev] host1.example.gzaidman.com [test] host[2:3].example.gzaidman.com [prod] host[4:5].example.gzaidman.com a single host can be members of multiple groups and a group can contain child groups with the :children syntax. Let\u0026rsquo;s say we want to also group the hosts by their location:\n[dev] host1.example.gzaidman.com [test] host[2:3].example.gzaidman.com [prod] host[4:5].example.gzaidman.com [england] host1.example.gzaidman.com host3.example.gzaidman.com [finland] host2.example.gzaidman.com host4.example.gzaidman.com [us] host5.example.gzaidman.com [europe:children] england finland In ansible there are two default groups that are always created:\n all: contains every host in the inventory. ungrouped: contains all hosts that don’t have another group aside from all.  To verify that the inventory is ok, we can use:\n# ansible HOST/GROUP --list-hosts ansible canada --list-hosts Adding variables to managed hosts Very often we will want to define variables that are specific to a host or a group of hosts.\nWe can add the variables directly on each host\n[test] host1.example.gzaidman.com listen_port=4321 host2.example.gzaidman.com listen_port=8642 We can also add variables for a group:\n[test:vars] ntp_server=ntp.canada.example.com ntp_port=4567 proxy=proxy.canada.example.com Those variables are called host and group variables and they will be available in the playbook on the host. Host and group variables are very common but defining them directly on the inventory file can make it very verbose and hard to read especially when we have a large inventory file. Ansible lets us organize host and group variables on separate files which will make our inventory cleaner and our project more maintainable. We need to create host_vars and group_vars directories, those directories can contain a file with the name of the host/group where we will define all the variables. For example we can take the inventory above, and create:\n[gzaidman:example] tree . ├── group_vars │ └── test ├── host_vars │ ├── host1.example.gzaidman.com │ └── host2.example.gzaidman.com └── inventory The variable files should be in yaml syntax only which is a bit different from the above.\n[gzaidman:example]cattestntp_server:ntp.canada.example.comntp_port:4567proxy:proxy.canada.example.com[gzaidman:example]cathost1.example.gzaidman.comlisten_port:4321[gzaidman:example]cathost2.example.gzaidman.comlisten_port:8642You can also create directories named after your groups or hosts and place variable files in them. Ansible will read all the files in these directories in lexicographical order. An example with the \u0026lsquo;test\u0026rsquo; group:\n./example/group_vars/test/ntp_settings ./example/group_vars/test/proxy_settings\nThis can be very useful to keep your variables organized when a single file gets too big, or when you want to use Ansible Vault (covered later) on some group variables.\nInventory Location: The inventory can be in the following locations (ordered by precedence):\n parameter: ansible/ansible-playbook \u0026ndash;inventory PATHNAME or -i PATHNAME. Ansible configuration: with the inventory=INVENTORY_PATH. default location: /etc/ansible/host system\u0026rsquo;s default static inventory file.  Configurations There are a lot of flags we can set to control the way ansible connects to our hosts. We define does as inventory variables for a specific host/group. For the full list of configurations visit the Docs.\nSome of the most common ones are:\n ansible_connection: The why ansible will try to connect to the host. Bt default ansible executes playbooks over SSH with a connection type called smart, but there are other connection types:  SSH Based: paramiko, ssh Non-SSH based: local, docker   ansible_host: The name of the host to connect to, if different from the alias you wish to give to it. ansible_port: The connection port number, if not the default (22 for ssh).  Examples To see examples on different inventories go to the docs on:\nhttps://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#inventory-setup-examples\nDynamic Inventory When working with numerous machines or in an environment where machines come and go very quickly, it can be hard to keep the static inventory files up-to-date. Ansible supports dynamic inventory scripts that retrieve current information from external sources, allowing the inventory to be created in real time based on the current env. These scripts collect information from an external source and create JSON format inventory files.\nIf the inventory file is executable, then it is treated as a dynamic inventory program and Ansible attempts to run it to generate the inventory. If the file is not executable, then it is treated as a static inventory.\nIf a dynamic inventory script does not exist for the infrastructure in use, you can write a custom dynamic inventory program. This is a link to the ansible doc for writing a dynamic inventory link. A few things we should keep in mind:\n Can be written in any programming language, but must have an appropriate interpreter line (for example, #!/usr/bin/python). The script should return inventory information in JSON format. When passed the \u0026ndash;list option, the script must print a JSON-encoded hash/dictionary of all the hosts and groups in the inventory. When passed the \u0026ndash;host HOST option, the script must print a JSON hash/dictionary consisting of variables that are associated with that host, or an empty JSON hash/dictionary.  Configuring Ansible On each ansible project it is recommended to create a configuration file to override the default configurations based on the project requirements. Ansible configuration file is located at /etc/ansible/ansible.cfg, to override some settings we need to create a project configuration file at the project root directory with the same name ansible.cfg. The stock configuration should be sufficient for most project, and you can examine the /etc/ansible/ansible.cfg file to see the default configuration you can override.\nThe Ansible configuration file consists of several sections, each section is enclosed with \u0026lsquo;[SECTION_NAME]\u0026rsquo;.\nWe will talk about two sections that relate to the way ansible connects to hosts.\nSome configurations which relate to host management (they can als be overridden at the playbook level):\n[defaults]\nThis is the first section in the file and it sets defaults for Ansible operation.\n inventory - Specifies the path to the inventory file. remote_user - specify a different remote user, by default it will try to log in with the user which ran the ansible command via SSH. ask_pass - Whether or not to prompt for an SSH password. Can be false if using SSH public key authentication.  [privilege_escalation]\nConfigures how Ansible performs privilege escalation on managed hosts\n become - Whether to automatically switch user on the managed host after connecting. This can also be specified by a play. become_method - How to switch user (default is sudo). become_user - The user to switch to on the managed host (default is root). become_ask_pass - Whether to prompt for a password for your become_method. Defaults to false.  We can see all the configuration options with the ansible-config list command.\n** It\u0026rsquo;s important to understand that the above options on the default section refer to the initial connections meaning how to connect to the host and the options on the privilege_escalation refer to what to do once you are connected.\nConfiguration File Precedence  ANSIBLE_CONFIG environment variable ./ansible.cfg ~/ansible.cfg /etc/ansible/ansible.cfg  The recommended practice is to create an ansible.cfg file in a directory from which you run Ansible commands (meaning option 2). We cab check which configuration file is being used with ansible \u0026ndash;version.\n","permalink":"https://gal-zaidman.github.io/blog/ansible/2.-managing-hosts-with-ansible/","tags":["Ansible","FullCourse","GettingStarted"],"title":"Managing Hosts With Ansible"},{"categories":["Ansible","Full course"],"contents":"What is Ansible Ansible is an open source automation platform which is being developed by Redhat, it has a very large community of developers from simple users to huge organization. Ansible is an \u0026ldquo;infrastructure as Code\u0026rdquo; language, that means you can define and describe the state you want your infrastructure to be in with simple text file that can be managed and shared on a version control system.Ansible is a simple yaml based automation language that aims to make infrastructure management much more simple and maintainable. No more maintaining huge shell scripts that were written by some guy 2 years ago and now everyone is afraid of touching them! when we write our scripts in ansible we know that after a few years new eyes can look at them and understand the logic.\nEven though ansible aimed for Devops and IT professionals it is a great tool for every developer to have in their belt. It is very simple to learn, can save a lot of google searching and helps avoiding complex env problems by applying best practices.\nWhy use Ansible   Simple:\nSimpler is better. Ansible is designed so that its tools are simple to use and automation is simple to write and read. Ansible is very easy to read and understand even if you are a new developer that enters the team. There are no special coding skills needed to write and edit it, which help ensure that everyone understands what they do no black magic needed!.\n  Powerful:\nAnsible has roles that can deploy large applications or configure existing infrastructure in a clear way and with very few lines of code, as well as ansible modules which wrap a set of complex commands with clear documentation and configuration.\n  No complex configuration needed:\nAnsible doesn\u0026rsquo;t need to have specific software installed on the hosts it manages, it connects to them (usually with ssh) and manages them from the local machine so there is no agent or special software needed on the managed hosts.\n  Cross platform support:\nAnsible provides agentless support for Linux, Windows, UNIX, network devices, a wide range of cloud providers, and container environments.\n  This as been a very short introduction because from now we will learn and see a lot of examples. If you are still unsure what is ansible and why do you need it I advise you to take at the following guide.\n","permalink":"https://gal-zaidman.github.io/blog/ansible/1.-what-is-ansible-and-why/","tags":["Ansible","FullCourse","GettingStarted"],"title":"Ansible the What and Why"}]